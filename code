import json
import boto3
from datetime import datetime

# Initialize DynamoDB client
dynamodb = boto3.resource('dynamodb')

# Replace with your DynamoDB table name
DYNAMO_TABLE_NAME = 'my_table'

def lambda_handler(event, context):
    """
    Lambda function triggered by S3 events.
    Processes the event, reads S3 object metadata, and stores details in DynamoDB.
    """
    try:
        # Log the received event
        print(f"Received event: {json.dumps(event)}")
        
        # Extract S3 bucket and object details from the event
        for record in event['Records']:
            bucket_name = record['s3']['bucket']['name']
            object_key = record['s3']['object']['key']
            
            print(f"Bucket: {bucket_name}, Object Key: {object_key}")
            
            # Fetch object metadata from S3
            s3 = boto3.client('s3')
            response = s3.head_object(Bucket=bucket_name, Key=object_key)
            
            # Extract metadata
            file_size = response['ContentLength']
            content_type = response['ContentType']
            last_modified = response['LastModified'].isoformat()
            
            print(f"File Size: {file_size}, Content Type: {content_type}, Last Modified: {last_modified}")
            
            # Insert data into DynamoDB
            table = dynamodb.Table(DYNAMO_TABLE_NAME)
            table.put_item(
                Item={
                    'id': object_key,
                    'bucket_name': bucket_name,
                    'file_size': file_size,
                    'content_type': content_type,
                    'last_modified': last_modified,
                    'timestamp': datetime.utcnow().isoformat()
                }
            )
            print(f"Inserted item into DynamoDB table {DYNAMO_TABLE_NAME}")

    except Exception as e:
        print(f"Error processing event: {e}")
        raise e

    return {
        'statusCode': 200,
        'body': json.dumps('Event processed successfully!')
    }
